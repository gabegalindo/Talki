# app.py
# -*- coding: utf-8 -*-
import os
import uuid
import tempfile
from flask import Flask, request, jsonify, send_file
from flasgger import Swagger, swag_from
from flask_cors import CORS

# --- ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸ ---
import services

# --- Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ë° ê¸°ë³¸ ì„¤ì • ---
app = Flask(__name__)
CORS(app) # ëª¨ë“  ë„ë©”ì¸ì—ì„œì˜ ìš”ì²­ì„ í—ˆìš© (ê°œë°œìš©)

# --- Swagger UI ì„¤ì • ---
SWAGGER_TEMPLATE = {
    "swagger": "2.0",
    "info": {
        "title": "AI Character API",
        "description": "Vertex AIì™€ GCP ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•œ ì´ë¯¸ì§€ ìƒì„±, ëŒ€í™”í˜• AI API ë¬¸ì„œì…ë‹ˆë‹¤.",
        "version": "1.0.0"
    },
    "basePath": "/",
    "schemes": ["http", "https"]
}
swagger = Swagger(app, template=SWAGGER_TEMPLATE)


# --- í´ë” ìƒì„± ---
os.makedirs('static/generated_audio', exist_ok=True)
os.makedirs('static/generated_image', exist_ok=True)

# === API ì—”ë“œí¬ì¸íŠ¸ ===

@app.route("/")
def index():
    """ë£¨íŠ¸ ê²½ë¡œ. API ì„œë²„ê°€ ë™ì‘ ì¤‘ì„ì„ ì•Œë¦¬ê³  API ë¬¸ì„œ ë§í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
    return """
    <h1>AI API ì„œë²„ê°€ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.</h1>
    <p>API ë¬¸ì„œëŠ” <a href="/apidocs/">/apidocs/</a> ì—ì„œ í™•ì¸í•˜ì„¸ìš”.</p>
    """

# --- 1. ì´ë¯¸ì§€ ìƒì„± API (/api/generate-image) ---
@app.route('/api/generate-image', methods=['POST'])
@swag_from({
    'tags': ['Image Generation'],
    'summary': 'ìºë¦­í„° ì†ì„±ì„ ë°›ì•„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  PNG íŒŒì¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.',
    'requestBody': {
        'required': True,
        'content': {
            'application/json': {
                'schema': {
                    'type': 'object',
                    'properties': {
                        'color': {'type': 'string', 'example': 'blue'},
                        'animal': {'type': 'string', 'example': 'fox'},
                        'background': {'type': 'string', 'example': 'snowy field'},
                        'emotion': {'type': 'string', 'example': 'happy'}
                    },
                    'required': ['color', 'animal', 'background', 'emotion']
                }
            }
        }
    },
    'responses': {   
        '200': {'description': 'ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ. PNG ì´ë¯¸ì§€ íŒŒì¼ì´ ë°˜í™˜ë©ë‹ˆë‹¤.','content': {'image/png': {'schema': {'type': 'string', 'format': 'binary'}}}},
        '400': {'description': 'ì˜ëª»ëœ ìš”ì²­ (í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½ ë“±)'},
        '500': {'description': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ (ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨)'}
    }
})
def api_generate_image():
    if not request.json:
        return jsonify({"error": "ìš”ì²­ ë³¸ë¬¸ì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤."}), 400

    required_params = ['color', 'animal', 'background', 'emotion']
    if not all(param in request.json for param in required_params):
        return jsonify({"error": f"í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(required_params)}"}), 400

    prompt = f"Chibi {request.json['color']} {request.json['animal']} character, 2D flat illustration, big sparkling eyes, {request.json['emotion']} expression, rounded and soft body, icon style, on a {request.json['background']}"

    try:
        output_path = os.path.join('static', 'generated_image', f"{uuid.uuid4()}.png")
        if not services.generate_image_service(prompt, output_path):
            raise Exception("ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤ì—ì„œ ì˜¤ë¥˜ ë°œìƒ")
        
        return send_file(output_path, mimetype='image/png')

    except Exception as e:
        print(f"ğŸš¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"error": "ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500

# --- 2. ëŒ€í™”í˜• API (/api/conversation) ---
@app.route('/api/conversation', methods=['POST'])
@swag_from({
    'tags': ['Conversation'],
    'summary': 'ì‚¬ìš©ì ìŒì„±ì„ ë°›ì•„ AIì˜ ë‹µë³€ í…ìŠ¤íŠ¸ì™€ ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤.',
    'requestBody': {
        'required': True,
        'content': {
            'multipart/form-data': {
                'schema': {'type': 'object', 'properties': {'audio_file': {'type': 'string', 'format': 'binary', 'description': 'ì‚¬ìš©ìì˜ ìŒì„± íŒŒì¼ (webm)'}}, 'required': ['audio_file']}
            }
        }
    },
    'responses': {
        '200': {
            'description': 'ëŒ€í™” ì²˜ë¦¬ ì„±ê³µ',
            'content': {
                'application/json': {
                    'schema': {
                        'type': 'object',
                        'properties': {
                            'user_text': {'type': 'string', 'example': 'ì˜¤ëŠ˜ ë‚ ì”¨ ì •ë§ ì¢‹ë„¤ìš”!'},
                            'response_text': {'type': 'string', 'example': 'ë„¤, ì •ë§ í™”ì°½í•˜ë„¤ìš”! ê°™ì´ ì‚°ì±…ì´ë¼ë„ ê°ˆê¹Œìš”?'},
                            'response_audio_url': {'type': 'string', 'example': 'http://localhost:8000/static/generated_audio/some_uuid.mp3'}
                        }
                    }
                }
            }
        },
        '400': {'description': 'ì˜ëª»ëœ ìš”ì²­ (íŒŒì¼ ëˆ„ë½ ë“±)'},
        '500': {'description': 'ì„œë²„ ë‚´ë¶€ ì²˜ë¦¬ ì˜¤ë¥˜'}
    }
})
def api_conversation():
    if 'audio_file' not in request.files:
        return jsonify({"error": "ìš”ì²­ì— 'audio_file'ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."}), 400

    file = request.files['audio_file']
    if file.filename == '':
        return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    with tempfile.TemporaryDirectory() as temp_dir:
        try:
            webm_path = os.path.join(temp_dir, 'upload.webm')
            file.save(webm_path)

            wav_path = os.path.join(temp_dir, 'converted.wav')
            if not services.convert_webm_to_wav(webm_path, wav_path):
                raise Exception("ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨")

            user_text = services.transcribe_audio(wav_path)
            if user_text is None:
                raise Exception("ìŒì„± ì¸ì‹(STT) ì‹¤íŒ¨")
            if not user_text.strip():
                user_text = "(âŒ Could not recognize speech âŒ)"

            response_text = services.generate_conversational_response(user_text)
            
            user_emotion = services.analyze_emotion_with_gemini(user_text)
            
            output_filename = f"{uuid.uuid4()}.mp3"
            output_path = os.path.join('static', 'generated_audio', output_filename)
            
            if not services.text_to_speech_service(response_text, output_path, emotion=user_emotion):
                raise Exception("âŒ ìŒì„± íŒŒì¼(TTS) ìƒì„± ì‹¤íŒ¨ âŒ")
            
            audio_url = request.host_url + output_path
            
            return jsonify({
                "user_text": user_text,
                "response_text": response_text,
                "response_audio_url": audio_url
            })

        except Exception as e:
            print(f"ğŸš¨ ëŒ€í™”í˜• API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return jsonify({"error": "ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500

# --- ì„œë²„ ì‹¤í–‰ ---
if __name__ == '__main__':
    print("--- AI API ì„œë²„ ì‹œì‘ ---")
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ GCP ì„¤ì • ë¡œë“œ
    project_id = os.getenv("GCP_PROJECT_ID")
    # Gemini ëª¨ë¸ì„ ìœ„í•´ ì§€ì›ë˜ëŠ” ë¦¬ì „ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
    location = os.getenv("GCP_LOCATION", "asia-northeast1") 

    if not project_id:
        print("ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: GCP_PROJECT_ID í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)

    print(f"í”„ë¡œì íŠ¸ ID: {project_id}, ë¦¬ì „: {location}")
    
    # ì„œë²„ ì‹œì‘ ì „ Vertex AI ë° ëª¨ë¸ ì´ˆê¸°í™”
    if services.initialize_vertex_ai(project_id, location):
        print("ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (Port: 8000)")
        app.run(host='0.0.0.0', port=8000, debug=False) # ë°°í¬ ì‹œì—ëŠ” debug=False ê¶Œì¥
    else:
        print("ğŸš¨ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë° ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì„œë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)