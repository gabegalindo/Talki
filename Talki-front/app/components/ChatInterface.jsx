// ChatInterface.jsx

"use client";

import { useState, useEffect, useRef } from "react";
import styles from "./ChatInterface.module.css";
import Avatar from "./Avatar";

export default function ChatInterface({ character, onSpeakingChange }) {
  const [messages, setMessages] = useState([]);
  const [userInput, setUserInput] = useState("");
  const [isRecording, setIsRecording] = useState(false);
  const [showKeyboard, setShowKeyboard] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false); // STT -> TTS Ï†ÑÏ≤¥ Í≥ºÏ†ïÏùÑ Ï≤òÎ¶¨ÌïòÎäî ÏÉÅÌÉú
  const [typingText, setTypingText] = useState(''); // ÌÉÄÏù¥Ìïë Ï§ëÏù∏ ÌÖçÏä§Ìä∏
  const [typingMessageId, setTypingMessageId] = useState(null); // ÌÉÄÏù¥Ìïë Ï§ëÏù∏ Î©îÏãúÏßÄ ID
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const chatEndRef = useRef(null);
  const audioRef = useRef(null);

  // Ï¥àÍ∏∞ Î©îÏãúÏßÄ ÏÑ§Ï†ï
  useEffect(() => {
    setMessages([
      {
        id: 1,
        text: `Hi! I'm your new ${character.trait} buddy ${character.type}! What should we talk about? üòÑ`,
        sender: "bot",
      },
    ]);
  }, [character]);

  // Î©îÏãúÏßÄ Î™©Î°ùÏù¥ ÏóÖÎç∞Ïù¥Ìä∏Îê† ÎïåÎßàÎã§ Îß® ÏïÑÎûòÎ°ú Ïä§ÌÅ¨Î°§
  useEffect(() => {
    chatEndRef.current?.scrollIntoView({ behavior: "smooth", block: "nearest"});
  }, [messages]);

  // ÏùåÏÑ± Ïû¨ÏÉù ÏÉÅÌÉúÎ•º Í¥ÄÎ¶¨ÌïòÎäî ref
  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const handlePlay = () => onSpeakingChange?.(true);
    const handlePause = () => onSpeakingChange?.(false);
    const handleEnded = () => onSpeakingChange?.(false);

    audio.addEventListener('play', handlePlay);
    audio.addEventListener('pause', handlePause);
    audio.addEventListener('ended', handleEnded);

    return () => {
      audio.removeEventListener('play', handlePlay);
      audio.removeEventListener('pause', handlePause);
      audio.removeEventListener('ended', handleEnded);
    };
  }, [onSpeakingChange]);

  // Ïª¥Ìè¨ÎÑåÌä∏ Ïñ∏ÎßàÏö¥Ìä∏ Ïãú Ï†ïÎ¶¨
  useEffect(() => {
    return () => {
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }
    };
  }, []);

  // ÌÇ§Î≥¥Îìú ÏûÖÎ†• Ï≤òÎ¶¨
  const handleSendMessage = (e) => {
    e.preventDefault();
    if (!userInput.trim()) return;

    const newUserMessage = {
      id: Date.now(),
      text: userInput,
      sender: "user",
    };
    setMessages((prev) => [...prev, newUserMessage]);
    setUserInput("");
    // TODO: ÌÇ§Î≥¥Îìú ÏûÖÎ†•ÎèÑ ÎåÄÌôîÌòï APIÏôÄ Ïó∞ÎèôÌïòÎäî Î°úÏßÅ Ï∂îÍ∞Ä ÌïÑÏöî
  };

  // ÏùåÏÑ± Ïû¨ÏÉù Ìï®Ïàò
  const playAudio = (audioUrl) => {
    if (!audioRef.current) {
      audioRef.current = new Audio();
    }
    
    audioRef.current.src = audioUrl;
    audioRef.current.play().catch(e => console.error("Audio play error:", e));
  };

  // ÏùåÏÑ± ÏûÖÎ†• Î∞è AI ÎåÄÌôî Ï≤òÎ¶¨
  const handleMicClick = async () => {
    if (isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
      mediaRecorderRef.current = recorder;
      audioChunksRef.current = [];

      recorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      // ÎÖπÏùåÏù¥ Ï§ëÏßÄÎêòÎ©¥ Ïã§ÌñâÎê† Î°úÏßÅ
      recorder.onstop = async () => {
        setIsProcessing(true); // Ï†ÑÏ≤¥ Ï≤òÎ¶¨ ÏãúÏûëÏùÑ ÏïåÎ¶º
        const audioBlob = new Blob(audioChunksRef.current, { type: "audio/webm" });
        const formData = new FormData();
        formData.append("audio_file", audioBlob, "recording.webm");

        try {
          const res = await fetch("http://localhost:8000/api/conversation", {
            method: "POST",
            body: formData,
          });

          if (!res.ok) {
            const errorData = await res.json();
            throw new Error(errorData.error || "ÎåÄÌôî Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.");
          }

          const data = await res.json();
          // data = { user_text, response_text, response_audio_url }

          // ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄÎ•º Ï±ÑÌåÖÏ∞ΩÏóê Ï∂îÍ∞Ä
          const newUserMessage = {
            id: Date.now(),
            text: data.user_text,
            sender: "user",
            isFromSTT: true
          };

          // AI ÏùëÎãµ Î©îÏãúÏßÄ Ï§ÄÎπÑ (ÌÖçÏä§Ìä∏Îäî ÎπÑÏõåÎëêÍ≥† ÎÇòÏ§ëÏóê Ï±ÑÏõÄ)
          const botResponse = {
            id: Date.now() + 1,
            text: '',
            sender: "bot",
            isTyping: true
          };
          
          // AI ÏùëÎãµ Î©îÏãúÏßÄÎ•º Î®ºÏ†Ä Ï∂îÍ∞Ä (ÌÖçÏä§Ìä∏Îäî ÎπÑÏñ¥ÏûàÏùå)
          setMessages((prev) => [...prev, newUserMessage]);
          setMessages((prev) => [...prev, botResponse]);
          setTypingMessageId(botResponse.id);
          
          // ÌÉÄÏù¥Ìïë Ìö®Í≥º ÏãúÏûë
          let i = 0;
          const typingInterval = setInterval(() => {
            if (i < data.response_text.length) {
              setTypingText(data.response_text.substring(0, i + 1));
              i++;
            } else {
              clearInterval(typingInterval);
              setTypingMessageId(null);
              setTypingText('');
              
              // ÌÉÄÏù¥ÌïëÏù¥ ÎÅùÎÇòÎ©¥ Ïã§Ï†ú Î©îÏãúÏßÄÎ°ú ÍµêÏ≤¥
              setMessages(prev => 
                prev.map(msg => 
                  msg.id === botResponse.id 
                    ? { ...msg, text: data.response_text, isTyping: false }
                    : msg
                )
              );
              
              // TTS Ïû¨ÏÉù (ÏùëÎãµÏù¥ ÏôÑÏÑ±Îêú ÌõÑÏóê Ïû¨ÏÉù)
              if (data.response_audio_url) {
                playAudio(data.response_audio_url);
              }
            }
          }, 30); // ÌÉÄÏù¥Ìïë ÏÜçÎèÑ Ï°∞Ï†à (ms)

        } catch (err) {
          console.error("Conversation API error:", err);
          const errorMessage = {
            id: Date.now(),
            text: `Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: ${err.message}`,
            sender: "system",
            isError: true
          };
          setMessages((prev) => [...prev, errorMessage]);
        } finally {
          setIsProcessing(false); // Ï†ÑÏ≤¥ Ï≤òÎ¶¨ ÏôÑÎ£å
        }
      };

      recorder.start();
      setIsRecording(true);
    } catch (err) {
      console.error("Mic error:", err);
      const errorMessage = {
        id: Date.now(),
        text: `ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑º Ïò§Î•ò: ${err.message}`,
        sender: "system",
        isError: true
      };
      setMessages((prev) => [...prev, errorMessage]);
    }
  };

  return (
    <div className={styles.chatContainer}>
      <header className={styles.chatHeader}>
        <Avatar color={character.color} type={character.type} isSpeaking={isProcessing} />
        <div className={styles.characterInfo}>
          <span className={styles.characterName}>{character.name} </span>
          <span className={styles.characterStatus}>Online</span>
        </div>
      </header>

      <div className={styles.messageList}>
        {messages.map((msg) => (
          <div
            key={msg.id}
            className={`${styles.messageBubble} ${
              msg.sender === "user" ? styles.userMessage : styles.botMessage
            } ${msg.isError ? styles.errorMessage : ''} ${msg.isTyping ? styles.typing : ''}`}
          >
            {msg.id === typingMessageId ? typingText : msg.text}
            {msg.isTyping && <span className={styles.cursor}>|</span>}
          </div>
        ))}
        {isProcessing && (
          <div className={`${styles.messageBubble} ${styles.typingIndicator}`}>
            AI is creating response...
          </div>
        )}
        <div ref={chatEndRef} />
      </div>

      <form onSubmit={handleSendMessage} className={styles.inputArea}>
        {showKeyboard ? (
          <>
            <input
              type="text"
              value={userInput}
              onChange={(e) => setUserInput(e.target.value)}
              placeholder="Type your message..."
              className={styles.textInput}
            />
            <button type="submit" className={styles.sendButton}>
              Send
            </button>
            <button
              type="button"
              className={styles.micSmallButton}
              onClick={() => setShowKeyboard(false)}
              aria-label="Switch back to mic"
            >
              üé§
            </button>
          </>
        ) : (
          <div className={styles.micContainer}>
            <div className={styles.micGroup}>
              <button
                type="button"
                className={`${styles.micMainButton} ${isRecording ? styles.recording : ''}`}
                onClick={handleMicClick}
                aria-label={isRecording ? "Stop recording" : "Start talking"}
              >
                {isRecording ? '‚èπ' : 'üé§'}
              </button>

              {isRecording && (
                <span className={styles.recordingIndicator}>Recording...</span>
              )}
            </div>

            <button
              type="button"
              className={styles.keyboardButton}
              onClick={() => setShowKeyboard(true)}
              aria-label="Use keyboard"
            >
              ‚å®Ô∏è
            </button>
          </div>
        )}
      </form>
    </div>
  );
}